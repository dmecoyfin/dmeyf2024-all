{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJz8GT5QDbbR"
   },
   "source": [
    "## Instrucciones:\n",
    "\n",
    "Este archivo es una plantilla que deberás completar para la creación de un job que permita ejecutar tu experimento asignado. Es importante reemplazar el nombre genérico del archivo por un identificador único, que será el número asignado al alumno que lo creó. Cada vez que otro alumno utilice ese job, se recompensará al autor original.\n",
    "\n",
    "El job debe ser ejecutable simplemente configurando correctamente las siguientes secciones:\n",
    "- **Parámetros**\n",
    "- **Input**\n",
    "- **Output**\n",
    "\n",
    "El archivo debe ser obligatoriamente un *Jupyter Notebook*, con el fin de facilitar su uso a los alumnos menos técnicos. Sin embargo, si prefieres migrar o adaptar el código a archivos planos para tus propios pipelines, podrás hacerlo, siempre que quede claro el origen del código.\n",
    "\n",
    "El formato del nombre del job debe seguir la siguiente convención:\n",
    "- `j<id_alumno>_<ref>.ipynb`\n",
    "\n",
    "Cada alumno puede generar más de un job, y también puede modificar los jobs de otros, siempre que se respete el nombre original.\n",
    "\n",
    "Para la entrega de la segunda competencia, debes incluir dos componentes:\n",
    "1. Todos los jobs utilizados, con sus nombres originales.\n",
    "2. Un archivo explicando la secuencia en la que se ejecutaron los jobs.\n",
    "\n",
    "Los jobs se compartirán en las slides de los experimentos con el link al repo de github.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_xvJXPhCkMA"
   },
   "source": [
    "# “Trazas de información ocultas bajo el análisis de los valores SHAP”\n",
    "\n",
    "## Autor: Nahuel Alba\n",
    "## Fecha de última modificación: <ie: 06/11/2024>\n",
    "## Descripción: Al modelo optimizado aplicado al dataset se le aplica el algoritmo Shap value y se utiliza la importancia de las feature para realizar selectivamente transformaciones en su distribución con el algoritmo Yeo-Johnson.\n",
    "\n",
    "< Completar >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRTSvXdLHkpB"
   },
   "source": [
    "## Parámetros\n",
    "\n",
    "< Descripción de cada uno de los parámetros que utiliza el job >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMU00Fl7IIfm"
   },
   "outputs": [],
   "source": [
    "# Semillas que se utilizaran \n",
    "semillas = random.sample(range(1, 1000), 100)\n",
    "# Parametros necesarios para calcular la ganancia\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "# Meses de entrenamiento y prueba\n",
    "mes_train = 202105\n",
    "mes_test = 202107\n",
    "# función para evaluar la ganancia\n",
    "def lgb_gan_eval(y_pred, data):\n",
    "    weight = data.get_weight()\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sH5VivJSIM42"
   },
   "source": [
    "## Input\n",
    "\n",
    "< Archivos de datos (csv.gz) con sus paths que van a consumirse por el job>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEk4Fj7VIv7g"
   },
   "outputs": [],
   "source": [
    "# Ingrese la ruta donde se encuentra el archivo de datos con clase ternaria \n",
    "\n",
    "data = pd.read_csv(r\"c:\\Users\\Admin\\Documents\\1_Notebook\\1_Estudio\\1_UBA_Maestria_DS\\1_Especializacion\\1_Segundo_Semestre\\DMEyF\\datasets\\competencia_2\\competencia_02_ct.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQ6MUhENI0Ya"
   },
   "source": [
    "## Output\n",
    "\n",
    "< Archivos, bases de datos, modelos que va a generar el job>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZT3kxlkFIv4p"
   },
   "outputs": [],
   "source": [
    "df_experimento_unido = df_ganancias_post.merge(df_ganancias_default, left_on='semilla_post', right_on='semilla_default')\n",
    "\n",
    "\n",
    "#ingrese path para guardar el archivo csv\n",
    "\n",
    "df_experimento_unido.to_csv(r\"C:\\Users\\Admin\\Documents\\1_Notebook\\1_Estudio\\1_UBA_Maestria_DS\\1_Especializacion\\1_Segundo_Semestre\\DMEyF\\experimento 1\\datasets\\df_experimento_unido.csv\", index=False)\n",
    "\n",
    "#output de mejora efectiva\n",
    "\n",
    "experimento_resultado = df_experimento_unido['mejora']>0\n",
    "experimento_resultado.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NtIT33WnJFx-"
   },
   "outputs": [],
   "source": [
    "## Procesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVe0GO1IJHtI"
   },
   "source": [
    "### Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2VG2xS_Ivq3"
   },
   "outputs": [],
   "source": [
    "# Ejemplo\n",
    "%pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LM2kY_WJj15"
   },
   "source": [
    "## Código del proceso\n",
    "\n",
    "< Todo el código a partir de aquí debe poder ejecutarse sin necesidad de parametrizar nada>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nr6BNGDUJkWd"
   },
   "outputs": [],
   "source": [
    "data['clase_peso'] = 1.0\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "data['clase_binaria'] = np.where(data['clase_ternaria']=='CONTINUA', 0, 1)\n",
    "df_train = data[data['foto_mes']<=mes_train]\n",
    "df_test = data[data['foto_mes']==mes_test]\n",
    "clase_peso = df_train['clase_peso']\n",
    "X_train = df_train.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_train =df_train['clase_binaria']\n",
    "X_test = df_test.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_test =df_test['clase_binaria']\n",
    "w_train = df_train.loc[X_train.index, 'clase_peso']\n",
    "w_data_test = df_test.loc[X_test.index, 'clase_peso']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train,\n",
    "                            label=Y_train,  # elegir la clase\n",
    "                            weight=clase_peso)\n",
    "\n",
    "test_data = lgb.Dataset(X_test, label= Y_test, weight=w_data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb default \n",
    "\n",
    "df_resultados_default = pd.DataFrame()\n",
    "df_ganancias_default = pd.DataFrame({'semilla_default': [],'ganancias_default': []})\n",
    "dicc_trazas_shap = {}\n",
    "\n",
    "\n",
    "for x in semillas:\n",
    "    params = {\n",
    "    'objective': 'binary',  # Puedes cambiar esto si tu problema es multiclase u otro tipo\n",
    "    'metric': 'binary_logloss',  # Cambia el metric si es necesario\n",
    "    'seed': x }\n",
    "    model_default = lgb.train(params, train_data)    \n",
    "    y_pred_default = model_default.predict(X_test)\n",
    "    ganancia = lgb_gan_eval(y_pred_default, test_data)\n",
    "    df_resultados_default[f'default_{x}'] = y_pred_default\n",
    "    df_ganancias_default = pd.concat([df_ganancias_default, pd.DataFrame([{'semilla_default': x, 'ganancias_default': ganancia}])], ignore_index=True)\n",
    "    explainer = shap.TreeExplainer(model_default)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    shap_df = pd.DataFrame(shap_values, columns = X_train.columns)\n",
    "    importancia_shap = pd.DataFrame(np.abs(shap_values).mean(0), columns = ['valores_shap'])\n",
    "    importancia_shap['variables'] = X_train.columns\n",
    "    importancia_shap = importancia_shap.sort_values(by = 'valores_shap', ascending = False)\n",
    "    df_trazas_shap = importancia_shap[importancia_shap['valores_shap'] == 0]\n",
    "    lista = df_trazas_shap['variables'].to_list()\n",
    "    dicc_trazas_shap[x] = lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model_default)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap_df = pd.DataFrame(shap_values, columns = X_train.columns)\n",
    "importancia_shap = pd.DataFrame(np.abs(shap_values).mean(0), columns = ['valores_shap'])\n",
    "importancia_shap['variables'] = X_train.columns\n",
    "importancia_shap = importancia_shap.sort_values(by = 'valores_shap', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trazas_shap = importancia_shap[importancia_shap['valores_shap'] == 0]\n",
    "lista = df_trazas_shap['variables'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in semillas:\n",
    "    dicc_trazas_shap[x] = lista\n",
    "    valores_skew = []\n",
    "    for variable in lista:\n",
    "        valores_skew = []\n",
    "        asimetria = skew(X_train[variable])\n",
    "        valores_skew.append(asimetria)  \n",
    "    df_trazas_shap['skew'] = valores_skew\n",
    "ejemplo = lgb.Dataset(X_train, label=Y_train, weight=clase_peso)\n",
    "df_ganancias_default['semilla_default'] = df_ganancias_default['semilla_default'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asimetria = skew(df['variable'])\n",
    "dicc_valores_skew = {}\n",
    "dicc_train_sets = {}\n",
    "dicc_test_sets = {}\n",
    "\n",
    "#creación datasets train\n",
    "for semilla in semillas:\n",
    "    dicc_train_sets[semilla] = pd.DataFrame(df_train)\n",
    "#creación datasets test\n",
    "for semilla in semillas:\n",
    "    dicc_test_sets[semilla] = pd.DataFrame(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ganancias_post = pd.DataFrame({'semilla_post': list(dicc_ganancia_post.keys()), 'ganancias_post': list(dicc_ganancia_post.values())})\n",
    "df_experimento_unido = df_ganancias_post.merge(df_ganancias_default, left_on='semilla_post', right_on='semilla_default')\n",
    "df_experimento_unido['ganancias_post'] = df_experimento_unido['ganancias_post'].apply(lambda x: x[1])\n",
    "df_experimento_unido['ganancias_default'] = df_experimento_unido['ganancias_default'].apply(lambda x: x[1])\n",
    "df_experimento_unido['mejora'] = df_experimento_unido['ganancias_post'] - df_experimento_unido['ganancias_default']\n",
    "experimento_resultado = df_experimento_unido['mejora']>0\n",
    "experimento_resultado.values"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
