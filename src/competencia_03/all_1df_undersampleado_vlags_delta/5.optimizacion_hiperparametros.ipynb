{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Configuración General."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\c678456\\AppData\\Local\\anaconda3\\envs\\dmeyf\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#1. Librerías.\n",
    "%run \"../librerias.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Constantes.\n",
    "#a. Generales.\n",
    "%run \"../constantes.ipynb\"\n",
    "\n",
    "#b. A definir por el usuario.\n",
    "dataset_undersampleado = dataset_file_fe_1_all_undersampleado_lagsdelta\n",
    "\n",
    "cantidad_meses_train = \"all\"\n",
    "ventana = 1\n",
    "\n",
    "mes_train = mes_train_all_menos_2_sin_rotas\n",
    "mes_test = mes_test\n",
    "\n",
    "storage_name = \"sqlite:///\" + db_path + \"optimization_lgbm.db\"\n",
    "study_name = f\"exp_lgbm_comp3_{cantidad_meses_train}_{ventana}_undersampling_lagsdelta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Funciones\n",
    "%run \"../funciones.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Lectura de datos.\n",
    "data_undersampleado = pd.read_parquet(dataset_undersampleado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Pequeño pre-procesamiento sobre los datos.\n",
    "#i. Cambio tipos de datos (Me lo toma como tipo de dato \"object\"...)\n",
    "data_undersampleado['ctrx_quarter_normalizado'] = data_undersampleado['ctrx_quarter_normalizado'].astype(float)\n",
    "\n",
    "#ii. Pesos.\n",
    "data_undersampleado['clase_peso'] = 1.0\n",
    "\n",
    "data_undersampleado.loc[data_undersampleado['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data_undersampleado.loc[data_undersampleado['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "\n",
    "#iii. Filtro Train.\n",
    "data_undersampleado = data_undersampleado[data_undersampleado['foto_mes'].isin(mes_train)]\n",
    "\n",
    "#iv. Separar en X e y después del undersampling para Optuna.\n",
    "X_train_undersampleado = data_undersampleado.drop(['clase_ternaria', 'clase_peso', 'clase_binaria'], axis=1)\n",
    "y_train_binaria_undersampleado = data_undersampleado['clase_binaria']\n",
    "w_train_undersampleado = data_undersampleado['clase_peso']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Optimización Hiperparámetros (OH) con cantidad_meses_train meses con df -ventana con ratios incluidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Funcion de optimización de hiperparámetros.\n",
    "def objective(trial): \n",
    "    # Rango de parámetros a buscar sus valores óptimos.\n",
    "    num_leaves = trial.suggest_int('num_leaves', 10, 200)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.005, 0.3) # mas bajo, más iteraciones necesita.\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 15, 900)\n",
    "    feature_fraction = trial.suggest_float('feature_fraction', 0.1, 1.0)\n",
    "    bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0)\n",
    "\n",
    "\n",
    "    # Parámetros que le voy a pasar al modelo.\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'min_data_in_leaf': min_data_in_leaf,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'seed': semillas[0],\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    # Creo el dataset para Light GBM.\n",
    "    train_data_ob = lgb.Dataset(X_train_undersampleado,\n",
    "                              label=y_train_binaria_undersampleado, # eligir la clase\n",
    "                              weight=w_train_undersampleado)\n",
    "    \n",
    "    # Entreno.\n",
    "    cv_results = lgb.cv(\n",
    "        params,\n",
    "        train_data_ob,\n",
    "        num_boost_round=1000, # modificar, subit y subir... y descomentar la línea inferior\n",
    "        callbacks=[lgb.early_stopping(int(50 + 5 / learning_rate))],\n",
    "        feval=lgb_gan_eval,\n",
    "        stratified=True,\n",
    "        nfold=5,\n",
    "        seed=semillas[0]\n",
    "    )\n",
    "    \n",
    "    # Calculo la ganancia máxima y la mejor iteración donde se obtuvo dicha ganancia.\n",
    "    max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "    best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "    # Guardamos cual es la mejor iteración del modelo\n",
    "    trial.set_user_attr(\"best_iter\", best_iter)\n",
    "\n",
    "    return max_gan * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Voy a realizar un estudio de Optuna para encontrar los mejores parámetros.\n",
    "#i. Creo la base de datos donde guardar los resultados.\n",
    "storage_name = storage_name\n",
    "\n",
    "study_name = study_name\n",
    "\n",
    "#ii. Creo el estudio.\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "#iii. Corro el estudio.\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Visualizo los resultados del estudio, para modificar los rangos de análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contour(study, params=['num_leaves','min_data_in_leaf'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
