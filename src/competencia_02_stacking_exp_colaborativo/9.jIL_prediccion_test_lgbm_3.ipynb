{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Configuraciones Generales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Librerías.\n",
    "%run \"./librerias.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Constantes.\n",
    "#i. Generales.\n",
    "%run \"./constantes.ipynb\"\n",
    "\n",
    "#ii. Particulares.\n",
    "#a. Mes de Test.\n",
    "mes_test = mes_test\n",
    "#b. Dataset post Future Engineering del modelo.\n",
    "dataset_input = datasets_path + 'competencia_02_eugenio_negrin.parquet'\n",
    "#c. Modelo optimizado del modelo.\n",
    "modelo = modelos_path + 'lgbm_eugenio_negrin.txt'\n",
    "#d. Path output con las predicciones del modelo para el período de interés.\n",
    "dataset_output = path_output_m3_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Funciones.\n",
    "%run \"./funciones.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Lectura de dataframes post-feature engineering (.csv o .parquet), y modelos ya optimizados previamente (.txt).\n",
    "data = pd.read_parquet(dataset_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Dividimos entre conjuntos de datos.\n",
    "#i. Datos a predecirr.\n",
    "test_data = data[data['foto_mes'] == mes_test]\n",
    "#ii. Borramos las columnas de no interés.\n",
    "X_test = test_data.drop(['clase_ternaria'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Obtenemos los hiperparámetros del modelo.\n",
    "model_lgb = lgb.Booster(model_file=modelo)\n",
    "params = model_lgb.params # Parámetros.\n",
    "best_iter = params[\"num_iterations\"]  # Mejor número de iteraciones guardado en el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Predicción de Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i. Predecimos propiamente dicho.\n",
    "predicciones = model_lgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ii. Le pegamos la probabilidad de ser \"BAJA\" a cada cliente.\n",
    "X_test['probabilidad'] = predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iii. Nos quedamos solamente con las columnas de interés.\n",
    "stacking_predictions = X_test[['numero_de_cliente', 'foto_mes', 'probabilidad']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iv. Renombramos.\n",
    "stacking_predictions.rename({\"probabilidad\":\"probabilidad_modelo3\"},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v. Exportamos.\n",
    "stacking_predictions.to_parquet(dataset_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmeyf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
