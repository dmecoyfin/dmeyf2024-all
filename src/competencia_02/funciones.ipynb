{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Funciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i. PSI.\n",
    "#3. Funciones.\n",
    "#i. PSI.\n",
    "def psi(expected, actual, buckets=10):\n",
    "\n",
    "    def psi_formula(expected_prop, actual_prop):\n",
    "        result = (actual_prop - expected_prop) * np.log(actual_prop / expected_prop)\n",
    "        return result\n",
    "\n",
    "    expected_not_null = expected.dropna()\n",
    "    actual_not_null = actual.dropna()\n",
    "\n",
    "    bin_edges = pd.qcut(expected_not_null, q=buckets, duplicates='drop').unique()\n",
    "    bin_edges2 = [edge.left for edge in bin_edges] + [edge.right for edge in bin_edges]\n",
    "    breakpoints = sorted(list(set(bin_edges2)))\n",
    "\n",
    "    expected_counts, _ = np.histogram(expected_not_null, bins=breakpoints)\n",
    "    actual_counts, _ = np.histogram(actual_not_null, bins=breakpoints)\n",
    "\n",
    "    expected_prop = expected_counts / len(expected_not_null)\n",
    "    actual_prop = actual_counts / len(actual_not_null)\n",
    "\n",
    "    psi_not_null = psi_formula(expected_prop, actual_prop).sum()\n",
    "\n",
    "    psi_null = 0\n",
    "\n",
    "    if expected.isnull().sum() > 0 and actual.isnull().sum() > 0 :\n",
    "      expected_null_percentage = expected.isnull().mean()\n",
    "      actual_null_percentage = actual.isnull().mean()\n",
    "      psi_null = psi_formula(expected_null_percentage, actual_null_percentage)\n",
    "\n",
    "    return psi_not_null + psi_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ii. Evaluación de Ganancia (LGBM).\n",
    "def lgb_gan_eval(y_pred, data):\n",
    "    weight = data.get_weight()\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iii. Probabilidad de Ganancia (LGBM).\n",
    "def ganancia_prob(y_pred, y_true, prop = 1):\n",
    "  ganancia = np.where(y_true == 1, ganancia_acierto, 0) - np.where(y_true == 0, costo_estimulo, 0)\n",
    "  return ganancia[y_pred >= 0.025].sum() / prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iv. Probabilidad de Ganancia (Random Forest).\n",
    "def ganancia_prob_rf(y_hat, y, prop=1, class_index=1, threshold=0.025):\n",
    "  @np.vectorize\n",
    "  def ganancia_row(predicted, actual, threshold=0.025):\n",
    "    return  (predicted >= threshold) * (ganancia_acierto if actual == \"BAJA+2\" else -costo_estimulo)\n",
    "\n",
    "  return ganancia_row(y_hat[:,class_index], y).sum() / prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v. Diferentes funciones y métodos para corregir el efecto de la inflación.\n",
    "def drift_uva(dataset, campos_monetarios, tb_indices):\n",
    "    print(\"inicio drift_UVA()\")\n",
    "    dataset = dataset.merge(tb_indices[['foto_mes', 'UVA']], on='foto_mes', how='left')\n",
    "    for campo in campos_monetarios:\n",
    "        dataset[campo] *= dataset['UVA']\n",
    "    dataset.drop(columns=['UVA'], inplace=True)\n",
    "    print(\"fin drift_UVA()\")\n",
    "    return dataset\n",
    "\n",
    "def drift_deflacion(dataset, campos_monetarios, tb_indices):\n",
    "    print(\"inicio drift_deflacion()\")\n",
    "    dataset = dataset.merge(tb_indices[['foto_mes', 'IPC']], on='foto_mes', how='left')\n",
    "    for campo in campos_monetarios:\n",
    "        dataset[campo] *= dataset['IPC']\n",
    "    dataset.drop(columns=['IPC'], inplace=True)\n",
    "    print(\"fin drift_deflacion()\")\n",
    "    return dataset\n",
    "\n",
    "# Función para estandarizar datos\n",
    "def drift_estandarizar(dataset, campos_drift):\n",
    "    print(\"inicio drift_estandarizar()\")\n",
    "    for campo in campos_drift:\n",
    "        dataset[campo + \"_normal\"] = dataset.groupby('foto_mes')[campo].transform(lambda x: (x - x.mean()) / x.std())\n",
    "        dataset.drop(columns=[campo], inplace=True)\n",
    "    print(\"fin drift_estandarizar()\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vi. Adaptación de la función de ganancia para Random Forest.\n",
    "def rf_gan_eval(y_true, y_pred_proba, weights):\n",
    "    # Define los parámetros de ganancia y costo\n",
    "    ganancia_acierto = 7800  # Ajusta según tus datos\n",
    "    costo_estimulo = 200  # Ajusta según tus datos\n",
    "    \n",
    "    # Calcular la ganancia en base a las predicciones y los pesos\n",
    "    ganancia = np.where(weights == 1.00002, ganancia_acierto, 0) - np.where(weights < 1.00002, costo_estimulo, 0)\n",
    "    \n",
    "    # Ordenar las ganancias de acuerdo a las probabilidades de la clase positiva\n",
    "    ganancia = ganancia[np.argsort(y_pred_proba)[::-1]]\n",
    "    \n",
    "    # Cálculo de ganancia acumulada y obtención de la máxima ganancia\n",
    "    ganancia_acumulada = np.cumsum(ganancia)\n",
    "    max_ganancia = np.max(ganancia_acumulada)\n",
    "    \n",
    "    return max_ganancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vi. Funciones para limpieza de variables rotas.\n",
    "def corregir_interpolar(dataset, campo, meses):\n",
    "    \"\"\"\n",
    "    Corrige valores interpolando entre datos adyacentes, respetando clientes.\n",
    "    \"\"\"\n",
    "    # Crear columnas con valores anteriores (lag) y siguientes (lead) dentro de cada cliente\n",
    "    dataset['v1'] = dataset.groupby('numero_de_cliente')[campo].shift(1)  # Valor anterior\n",
    "    dataset['v2'] = dataset.groupby('numero_de_cliente')[campo].shift(-1)  # Valor siguiente\n",
    "\n",
    "    # Calcular el promedio entre lag y lead\n",
    "    dataset['promedio'] = dataset[['v1', 'v2']].mean(axis=1, skipna=True)\n",
    "\n",
    "    # Sustituir los valores en los meses especificados con el promedio calculado\n",
    "    dataset.loc[dataset['foto_mes'].isin(meses), campo] = dataset.loc[\n",
    "        dataset['foto_mes'].isin(meses), 'promedio'\n",
    "    ]\n",
    "\n",
    "    # Eliminar columnas temporales\n",
    "    dataset.drop(columns=['v1', 'v2', 'promedio'], inplace=True)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def corregir_mice(dataset, campo, meses):\n",
    "    \"\"\"Usa imputación de datos tipo MICE para corregir valores.\"\"\"\n",
    "    # Simple implementación para imputar valores con muestras similares\n",
    "    imputador = SimpleImputer(strategy=\"most_frequent\")\n",
    "    dataset.loc[dataset['foto_mes'].isin(meses), campo] = imputador.fit_transform(\n",
    "        dataset.loc[dataset['foto_mes'].isin(meses), [campo]]\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "def asignar_na(dataset, campo, meses):\n",
    "    \"\"\"Asigna NA a los valores de un campo en los meses especificados.\"\"\"\n",
    "    if campo in dataset.columns:\n",
    "        dataset.loc[dataset['foto_mes'].isin(meses), campo] = np.nan\n",
    "    return dataset\n",
    "\n",
    "def corregir_atributo(dataset, campo, meses, metodo):\n",
    "    \"\"\"Corrige un campo dado un método.\"\"\"\n",
    "    if campo not in dataset.columns:\n",
    "        return dataset  # Si no existe el campo, no hace nada\n",
    "\n",
    "    if metodo == \"MachineLearning\":\n",
    "        dataset = asignar_na(dataset, campo, meses)\n",
    "    elif metodo == \"EstadisticaClasica\":\n",
    "        dataset = corregir_interpolar(dataset, campo, meses)\n",
    "    elif metodo == \"MICE\":\n",
    "        dataset = corregir_mice(dataset, campo, meses)\n",
    "    return dataset\n",
    "\n",
    "def corregir_rotas(dataset, metodo):\n",
    "    \"\"\"Aplica las correcciones a los campos dañados.\"\"\"\n",
    "    print(\"Inicio de corregir_rotas()\")\n",
    "    \n",
    "    atributos_y_meses = [\n",
    "        (\"active_quarter\", [202006]),  # 1\n",
    "        (\"internet\", [202006]),  # 2\n",
    "        (\"mrentabilidad\", [201905, 201910, 202006]),  # 3\n",
    "        (\"mrentabilidad_annual\", [201905, 201910, 202006]),  # 4\n",
    "        (\"mcomisiones\", [201905, 201910, 202006]),  # 5\n",
    "        (\"mactivos_margen\", [201905, 201910, 202006]),  # 6\n",
    "        (\"mpasivos_margen\", [201905, 201910, 202006]),  # 7\n",
    "        (\"mcuentas_saldo\", [202006]),  # 8\n",
    "        (\"ctarjeta_debito_transacciones\", [202006]),  # 9\n",
    "        (\"mautoservicio\", [202006]),  # 10\n",
    "        (\"ctarjeta_visa_transacciones\", [202006]),  # 11\n",
    "        (\"mtarjeta_visa_consumo\", [202006]),  # 12\n",
    "        (\"ctarjeta_master_transacciones\", [202006]),  # 13\n",
    "        (\"mtarjeta_master_consumo\", [202006]),  # 14\n",
    "        (\"ctarjeta_visa_debitos_automaticos\", [201904]),  # 15\n",
    "        (\"mttarjeta_visa_debitos_automaticos\", [201904]),  # 16\n",
    "        (\"ccajeros_propios_descuentos\", [201910, 202002, 202006, 202009, 202010, 202102]),  # 17\n",
    "        (\"mcajeros_propios_descuentos\", [201910, 202002, 202006, 202009, 202010, 202102]),  # 18\n",
    "        (\"ctarjeta_visa_descuentos\", [201910, 202002, 202006, 202009, 202010, 202102]),  # 19\n",
    "        (\"mtarjeta_visa_descuentos\", [201910, 202002, 202006, 202009, 202010, 202102]),  # 20\n",
    "        (\"ctarjeta_master_descuentos\", [201910, 202002, 202006, 202009, 202010, 202102]),  # 21\n",
    "        (\"mtarjeta_master_descuentos\", [201910, 202002, 202006, 202009, 202010, 202102]),  # 22\n",
    "        (\"ccomisiones_otras\", [201905, 201910, 202006]),  # 23\n",
    "        (\"mcomisiones_otras\", [201905, 201910, 202006]),  # 24\n",
    "        (\"cextraccion_autoservicio\", [202006]),  # 25\n",
    "        (\"mextraccion_autoservicio\", [202006]),  # 26\n",
    "        (\"ccheques_depositados\", [202006]),  # 27\n",
    "        (\"mcheques_depositados\", [202006]),  # 28\n",
    "        (\"ccheques_emitidos\", [202006]),  # 29\n",
    "        (\"mcheques_emitidos\", [202006]),  # 30\n",
    "        (\"ccheques_depositados_rechazados\", [202006]),  # 31\n",
    "        (\"mcheques_depositados_rechazados\", [202006]),  # 32\n",
    "        (\"ccheques_emitidos_rechazados\", [202006]),  # 33\n",
    "        (\"mcheques_emitidos_rechazados\", [202006]),  # 34\n",
    "        (\"tcallcenter\", [202006]),  # 35\n",
    "        (\"ccallcenter_transacciones\", [202006]),  # 36\n",
    "        (\"thomebanking\", [202006]),  # 37\n",
    "        (\"chomebanking_transacciones\", [201910, 202006]),  # 38\n",
    "        (\"ccajas_transacciones\", [202006]),  # 39\n",
    "        (\"ccajas_consultas\", [202006]),  # 40\n",
    "        (\"ccajas_depositos\", [202006, 202105]),  # 41\n",
    "        (\"ccajas_extracciones\", [202006]),  # 42\n",
    "        (\"ccajas_otras\", [202006]),  # 43\n",
    "        (\"catm_trx\", [202006]),  # 44\n",
    "        (\"matm\", [202006]),  # 45\n",
    "        (\"catm_trx_other\", [202006]),  # 46\n",
    "        (\"matm_other\", [202006])  # 47\n",
    "    ]\n",
    "\n",
    "    for atributo, meses in atributos_y_meses:\n",
    "        dataset = corregir_atributo(dataset, atributo, meses, metodo)\n",
    "\n",
    "    print(\"Fin de corregir_rotas()\")\n",
    "    return dataset\n",
    "\n",
    "def eliminar_atributo(dataset, atributo):\n",
    "    \"\"\"Elimina un atributo del dataset.\"\"\"\n",
    "    if atributo in dataset.columns:\n",
    "        dataset.drop(columns=[atributo], inplace=True)\n",
    "    return dataset"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
